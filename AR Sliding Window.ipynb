{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8028920e",
   "metadata": {},
   "source": [
    "# AR Sliding Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fe616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import itertools\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from IPython.display import display, HTML\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan, acorr_breusch_godfrey\n",
    "from statsmodels.api import OLS, add_constant\n",
    "from scipy.stats import shapiro, anderson\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "import pmdarima as pm\n",
    "from itertools import product\n",
    "from itertools import product\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display, Markdown\n",
    "from joblib import Parallel, delayed\n",
    "from matplotlib.dates import DateFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152e78ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pmdarima\n",
    "import numpy\n",
    "import scipy\n",
    "\n",
    "print(\"pmdarima:\", pmdarima.__version__)\n",
    "print(\"numpy:\", numpy.__version__)\n",
    "print(\"scipy:\", scipy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c596561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_excel('data/Monthly Mastersheet with Original Data.xlsx')\n",
    "# Ensure date is datetime and set index\n",
    "df['Month'] = pd.to_datetime(df['Month'])\n",
    "df.set_index('Month', inplace=True)\n",
    "df.index = pd.date_range(start=df.index[0], periods=len(df), freq='MS')\n",
    "df.columns = df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d43b656",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exog = pd.read_excel('data/All Exogenous Variables.xlsx')\n",
    "# Ensure date is datetime and set index\n",
    "df_exog['Month'] = pd.to_datetime(df_exog['Month'])\n",
    "df_exog.set_index('Month', inplace=True)\n",
    "df_exog.index = pd.date_range(start=df_exog.index[0], periods=len(df_exog), freq='MS')\n",
    "df_exog.columns = df_exog.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49a8c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=re.escape(\"'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\"),\n",
    "    category=FutureWarning,\n",
    "    module=r\"sklearn\\.utils\\.deprecation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372a2cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_list = ['LFPR', 'CPI', 'r', 'M1', 'GDP', 'IM', 'EX', 'CC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddd69a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = [\n",
    "    ('2019-07-01', '2022-02-01'),\n",
    "    ('2022-04-01', '2025-01-01'),\n",
    "    ('2020-06-01', '2025-01-01')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eb25a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model_assumptions(y_train, X_train, model_residuals):\n",
    "    model_residuals = model_residuals[4:]\n",
    "    assumptions = {}\n",
    "\n",
    "    if X_train.shape[1] > 0:\n",
    "        # Add constant\n",
    "        X_const = add_constant(X_train)\n",
    "\n",
    "        # Only run BP if enough columns\n",
    "        if X_const.shape[1] >= 2:\n",
    "            ols_model = OLS(y_train, X_const).fit()\n",
    "            bp_stat, bp_pvalue, _, _ = het_breuschpagan(ols_model.resid, X_const)\n",
    "            assumptions[\"Breusch-Pagan p\"] = bp_pvalue\n",
    "        else:\n",
    "            assumptions[\"Breusch-Pagan p\"] = np.nan\n",
    "    else:\n",
    "        assumptions[\"Breusch-Pagan p\"] = np.nan\n",
    "\n",
    "    # Normality\n",
    "    shapiro_stat, shapiro_p = shapiro(model_residuals)\n",
    "    ad_result = anderson(model_residuals)\n",
    "    assumptions[\"Shapiro p\"] = shapiro_p\n",
    "    assumptions[\"Anderson stat\"] = ad_result.statistic\n",
    "    assumptions[\"Anderson crit\"] = list(zip(ad_result.significance_level, ad_result.critical_values))\n",
    "\n",
    "    # Residual mean\n",
    "    assumptions[\"Mean resid\"] = model_residuals.mean()\n",
    "\n",
    "    # Autocorrelation\n",
    "    assumptions[\"Durbin-Watson\"] = durbin_watson(model_residuals)\n",
    "\n",
    "    return assumptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef60049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(y_true_train, y_pred_train, y_true_test, y_pred_test):\n",
    "    # Training R^2\n",
    "    # Exclude first 4 values from train RÂ² calculation\n",
    "    y_true_train_trimmed = y_true_train[4:]\n",
    "    y_pred_train_trimmed = y_pred_train[4:]\n",
    "    r2 = r2_score(y_true_train_trimmed, y_pred_train_trimmed)\n",
    "\n",
    "    # Test errors\n",
    "    mae = mean_absolute_error(y_true_test, y_pred_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true_test, y_pred_test))\n",
    "    # Handle possible zeros in true values for MAPE\n",
    "    y_true_test_nonzero = y_true_test.replace(0, np.nan).dropna()\n",
    "    y_pred_test_aligned = y_pred_test[y_true_test_nonzero.index]\n",
    "    mape = np.mean(np.abs((y_true_test_nonzero - y_pred_test_aligned) / y_true_test_nonzero)) * 100\n",
    "\n",
    "    return {'R2_train': r2, 'MAE_test': mae, 'RMSE_test': rmse, 'MAPE_test': mape}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c69264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(macro, exog, window, diff, seasonal_diff, show = False):\n",
    "    start_date, end_date = pd.to_datetime(window[0]), pd.to_datetime(window[1])\n",
    "\n",
    "    # Select y series and exog window\n",
    "    y = df[macro].loc[start_date:end_date].dropna().asfreq('MS')\n",
    "    exog = df_exog[exog].dropna().asfreq('MS')\n",
    "    exog_window = exog.loc[start_date:end_date].dropna().asfreq('MS')\n",
    "\n",
    "    # Align\n",
    "    y, exog_window = y.align(exog_window, join='inner')\n",
    "\n",
    "    # Train-test split\n",
    "    split_idx = int(len(y) * 0.8)\n",
    "    train, test = y[:split_idx], y[split_idx:]\n",
    "    exog_train, exog_test = exog_window[:split_idx], exog_window[split_idx:]\n",
    "\n",
    "    # AR model\n",
    "    model_ar = pm.auto_arima(\n",
    "        train,\n",
    "        start_p=1, start_q=0, start_P=0, start_Q=0, \n",
    "        max_p=5, max_q=5, max_P=2, max_Q=2, D=seasonal_diff, d = diff,\n",
    "        m=3,\n",
    "        seasonal=True,\n",
    "        stepwise=True,\n",
    "        suppress_warnings=True\n",
    "    )\n",
    "    forecast_ar, conf_int_ar = model_ar.predict(n_periods=len(test), return_conf_int=True)\n",
    "    fitted_ar = pd.Series(model_ar.predict_in_sample(), index=train.index)\n",
    "\n",
    "    # ARX model\n",
    "    model_arx = pm.auto_arima(\n",
    "        train,\n",
    "        X=exog_train,\n",
    "        seasonal=True,\n",
    "        m=3,\n",
    "        start_p=1, start_q=0, D = seasonal_diff, d = diff,\n",
    "        max_p=3, max_q=5,\n",
    "        max_P=2, max_Q=2,\n",
    "        stepwise=True,\n",
    "        trace=False,\n",
    "        suppress_warnings=True\n",
    "    )\n",
    "    forecast_arx, conf_int_arx = model_arx.predict( n_periods=len(test), X=exog_test, return_conf_int=True)\n",
    "    fitted_arx = pd.Series(model_arx.predict_in_sample(X=exog_train), index=train.index)\n",
    "\n",
    "    # Print orders\n",
    "    print(\"AR Order:\", model_ar.order, \"Seasonal:\", model_ar.seasonal_order)\n",
    "    print(\"ARX Order:\", model_arx.order, \"Seasonal:\", model_arx.seasonal_order)\n",
    "\n",
    "    print(\"\\n=== AR Model Summary ===\")\n",
    "    print(model_ar.arima_res_.summary())\n",
    "    print(\"\\n=== ARX Model Summary ===\")\n",
    "    print(model_arx.arima_res_.summary())\n",
    "\n",
    "    # Calculate metrics\n",
    "    metrics_ar = calc_metrics(train, fitted_ar, test, forecast_ar)\n",
    "    metrics_arx = calc_metrics(train, fitted_arx, test, forecast_arx)\n",
    "\n",
    "    if show:\n",
    "        sns.set(style=\"whitegrid\")\n",
    "        colors = {'Actual': 'black', 'AR Forecast': '#1f77b4', 'ARX Forecast': '#d62728'}\n",
    "        ci_colors = {'AR CI': '#aec7e8', 'ARX CI': '#ff9896'}\n",
    "        marker_styles = {'Actual': 'o', 'AR Forecast': 'x', 'ARX Forecast': '^'}\n",
    "\n",
    "        # Common date formatter for x-axis\n",
    "        date_fmt = DateFormatter('%Y-%m')\n",
    "\n",
    "        # Plot 1: Full window with both forecasts\n",
    "        exog_str = ', '.join(exog)\n",
    "        arx_label = f'ARX Forecast (with {exog_str})'\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(y.index, y, label='Actual', color=colors['Actual'])\n",
    "        plt.plot(test.index, forecast_ar, label='AR Forecast', linestyle='--', color=colors['AR Forecast'])\n",
    "        plt.plot(test.index, forecast_arx, label=arx_label, linestyle='--', color=colors['ARX Forecast'])\n",
    "        # plt.fill_between(test.index, conf_int_ar[:, 0], conf_int_ar[:, 1],\n",
    "        #                 color=ci_colors['AR CI'], alpha=0.3, label='AR 95% CI')\n",
    "        # plt.fill_between(test.index, conf_int_arx[:, 0], conf_int_arx[:, 1],\n",
    "        #                 color=ci_colors['ARX CI'], alpha=0.3, label='ARX 95% CI')\n",
    "        plt.axvline(x=test.index[0], color='gray', linestyle=':', label='Train/Test Split')\n",
    "        plt.title(f'{macro} Forecasts With and Without Crypto Volatility ({exog_str})', fontsize=16, weight='bold')\n",
    "        plt.xlabel('Date', fontsize=14)\n",
    "        plt.ylabel(macro, fontsize=14)\n",
    "        plt.gca().xaxis.set_major_formatter(date_fmt)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.legend(loc='best', fontsize=12)\n",
    "        plt.grid(True, alpha=0.5)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{macro}_forecast_plot.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "        # Plot 2: Zoomed in on test period\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(test.index, test, label='Actual', marker=marker_styles['Actual'],\n",
    "                color=colors['Actual'], linestyle='-', linewidth=1.5)\n",
    "        plt.plot(test.index, forecast_ar, label='AR Forecast', linestyle='--',\n",
    "                marker=marker_styles['AR Forecast'], color=colors['AR Forecast'], linewidth=1.5)\n",
    "        plt.plot(test.index, forecast_arx, label='ARX Forecast', linestyle='--',\n",
    "                marker=marker_styles['ARX Forecast'], color=colors['ARX Forecast'], linewidth=1.5)\n",
    "        # plt.fill_between(test.index, conf_int_ar[:, 0], conf_int_ar[:, 1],\n",
    "        #                 color=ci_colors['AR CI'], alpha=0.3, label='AR 95% CI')\n",
    "        # plt.fill_between(test.index, conf_int_arx[:, 0], conf_int_arx[:, 1],\n",
    "        #                 color=ci_colors['ARX CI'], alpha=0.3, label='ARX 95% CI')\n",
    "        plt.title(f'Test Period Forecast Comparison: {macro}', fontsize=16, weight='bold')\n",
    "        plt.xlabel('Date', fontsize=14)\n",
    "        plt.ylabel(macro, fontsize=14)\n",
    "        plt.gca().xaxis.set_major_formatter(date_fmt)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.legend(loc='best',fontsize=12)\n",
    "        plt.grid(True, alpha=0.5)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    # Check model assumption\n",
    "    # Get residuals (actual - fitted)\n",
    "    resid_ar = train - fitted_ar\n",
    "    resid_arx = train - fitted_arx\n",
    "\n",
    "    # Run assumption checks\n",
    "    assumptions_ar = check_model_assumptions(train, pd.DataFrame(index=train.index), resid_ar)\n",
    "    assumptions_arx = check_model_assumptions(train, exog_train, resid_arx)\n",
    "\n",
    "    # Combine and display metrics\n",
    "    metrics_df = pd.DataFrame([metrics_ar, metrics_arx], index=['AR', 'ARX'])\n",
    "    assumptions_df = pd.DataFrame([assumptions_ar, assumptions_arx], index=['AR', 'ARX'])\n",
    "    if show:\n",
    "        display(Markdown(\"### Model Forecast Accuracy Metrics\"))\n",
    "        display(metrics_df.style.set_table_styles([{'selector': 'th', 'props': [('font-weight', 'bold')]}]))\n",
    "        display(Markdown(\"### Model Assumption Check\"))\n",
    "        display(assumptions_df.style.set_table_styles([{'selector': 'th', 'props': [('font-weight', 'bold')]}]))\n",
    "\n",
    "    # Extract exogenous p-values from ARX model\n",
    "    exog_pvals = model_arx.arima_res_.pvalues\n",
    "    exog_pvals = exog_pvals[exog_train.columns.intersection(exog_pvals.index)]\n",
    "\n",
    "    return {\n",
    "        'metrics_ar': metrics_ar,\n",
    "        'metrics_arx': metrics_arx,\n",
    "        'model_ar_order': model_ar.order,\n",
    "        'model_ar_seasonal_order': model_ar.seasonal_order,\n",
    "        'model_arx_order': model_arx.order,\n",
    "        'model_arx_seasonal_order': model_arx.seasonal_order,\n",
    "        'assumptions_ar': assumptions_ar,\n",
    "        'assumptions_arx': assumptions_arx,\n",
    "        'exog_pvals': exog_pvals.to_dict(),\n",
    "        'y_test': test,\n",
    "        'y_pred': pd.Series(forecast_arx, index=test.index)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d10fad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model('CPI', ['USD Coin_lag4'], windows[0], diff=2, seasonal_diff = 0, show = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ca48fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_univariate_sarimax_screening(df_macro, df_exog, macro, window, diff, seasonal_diff, lag_prefix='Bitcoin', lag_range=7):\n",
    "    \"\"\"\n",
    "    Screens exogenous variables one-by-one and returns their p-values from ARX model.\n",
    "    \"\"\"\n",
    "    significance_results = []\n",
    "\n",
    "    for i in range(lag_range):\n",
    "        col = f\"{lag_prefix}_lag{i}\"\n",
    "        if col not in df_exog.columns:\n",
    "            print(f\"[SKIPPED] {col} not in df_exog\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            result = run_model(macro, [col], window, diff,seasonal_diff, show = False)\n",
    "            pval = result['exog_pvals'].get(col, None)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {col}: {e}\")\n",
    "            pval = None\n",
    "\n",
    "        significance_results.append((col, pval))\n",
    "\n",
    "    return pd.DataFrame(significance_results, columns=['Variable', 'P-Value']).sort_values(by='P-Value')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff14b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# asset_list= ['Bitcoin', 'Litecoin', 'XRP', 'Ethereum', 'Dogecoin', 'Cardano','Tether', 'USD Coin']\n",
    "# run_univariate_sarimax_screening(df, df_exog,'CC', windows[0], lag_prefix='Litecoin', lag_range=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ba69b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_crypto_screening(df_macro, df_exog, macro, window, diff, seasonal_diff, lag_range=7, pval_threshold=0.05):\n",
    "    asset_list = ['Bitcoin', 'Litecoin', 'XRP', 'Ethereum', 'Dogecoin', 'Cardano', 'Tether', 'USD Coin']\n",
    "    final_results = []\n",
    "\n",
    "    for asset in asset_list:\n",
    "        # Get candidate exog variables passing p-value threshold (assumed)\n",
    "        df_pvals = run_univariate_sarimax_screening(df_macro, df_exog, macro, window, diff, seasonal_diff, lag_prefix=asset, lag_range=lag_range)\n",
    "        df_pvals = df_pvals[df_pvals['P-Value'] < pval_threshold]\n",
    "\n",
    "        for _, row in df_pvals.iterrows():\n",
    "            col = row['Variable']\n",
    "            try:\n",
    "                result = run_model(macro, [col], window, diff, show=False)\n",
    "\n",
    "                baseline_mape = result['metrics_ar']['MAPE_test']\n",
    "                new_mape = result['metrics_arx']['MAPE_test']\n",
    "\n",
    "                improvement = (baseline_mape - new_mape) / baseline_mape * 100\n",
    "\n",
    "                final_results.append({\n",
    "                    'Variable': col,\n",
    "                    'P-Value': row['P-Value'],\n",
    "                    'Baseline MAPE': baseline_mape,\n",
    "                    'New MAPE': new_mape,\n",
    "                    'MAPE % Improvement': improvement\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] Running model for {col}: {e}\")\n",
    "                continue\n",
    "\n",
    "    df_final = pd.DataFrame(final_results)\n",
    "    if not df_final.empty:\n",
    "        df_final = df_final.sort_values(by='MAPE % Improvement', ascending=False)\n",
    "\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b54feb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro = 'LFPR'\n",
    "df_results = run_full_crypto_screening(df, df_exog, macro, windows[1], diff = 1, seasonal_diff = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd38265",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd63ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_excel('GDP_w2.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c63e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
