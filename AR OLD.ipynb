{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fcbea06",
   "metadata": {},
   "source": [
    "# Autoregressive Model Testing (SARIMA & SARIMAX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1d9e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import itertools\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from IPython.display import display, HTML\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan, acorr_breusch_godfrey\n",
    "from statsmodels.api import OLS, add_constant\n",
    "from scipy.stats import shapiro, anderson\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import seaborn as sns\n",
    "from scipy import stats \n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from itertools import product\n",
    "from itertools import product\n",
    "from tqdm import tqdm \n",
    "from joblib import Parallel, delayed\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08038013",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55220be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_excel('data/trimmed_Monthly Mastersheet Original Data.xlsx')\n",
    "# Ensure date is datetime and set index\n",
    "df['Month'] = pd.to_datetime(df['Month'])\n",
    "df.set_index('Month', inplace=True)\n",
    "df.index = pd.date_range(start=df.index[0], periods=len(df), freq='MS')\n",
    "df.columns = df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decdd21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exog = pd.read_excel('data/All Exogenous Variables.xlsx')\n",
    "# Ensure date is datetime and set index\n",
    "df_exog['Month'] = pd.to_datetime(df_exog['Month'])\n",
    "df_exog.set_index('Month', inplace=True)\n",
    "df_exog.index = pd.date_range(start=df_exog.index[0], periods=len(df_exog), freq='MS')\n",
    "df_exog.columns = df_exog.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6496c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_exog.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4930e188",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_list = ['LFPR', 'CPI', 'r', 'M1', 'GDP', 'IM', 'EX', 'CC']\n",
    "asset_list= ['Bitcoin', 'Tether', 'Litecoin', 'XRP', 'Ethereum', 'Dogecoin', 'Cardano', 'USD Coin']\n",
    "nonstable_list = ['Bitcoin', 'Litecoin', 'XRP', 'Ethereum', 'Dogecoin', 'Cardano']\n",
    "all_exog = df_exog.columns.to_list()\n",
    "stable_list = ['Tether', 'USD Coin']\n",
    "train_start = '2017-09-01'\n",
    "train_end = '2024-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4384d5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar_orders = {} \n",
    "ar_orders['LFPR'] = {'p': 1, 'd': 1, 'q': 0, 'P': 0, 'D': 1, 'Q': 0, 'Bitcoin_lag': 0, 'Tether_lag': 0, 'Litecoin_lag': 3, 'XRP_lag': 0, 'Ethereum_lag': 1, 'Dogecoin_lag': 5, 'Cardano_lag': 0, 'USD Coin_lag': 0} \n",
    "ar_orders['CPI'] = {'p': 1, 'd': 2, 'q': 0, 'P': 1, 'D': 1, 'Q': 0, 'Bitcoin_lag': 0, 'Tether_lag': 1, 'Litecoin_lag': 1, 'XRP_lag': 0, 'Ethereum_lag': 1, 'Dogecoin_lag': 1, 'Cardano_lag': 1, 'USD Coin_lag': 0} \n",
    "ar_orders['r'] = {'p': 1, 'd': 2, 'q': 0, 'P': 0, 'D': 1, 'Q': 0, 'Bitcoin_lag': 1, 'Tether_lag': 1, 'Litecoin_lag': 1, 'XRP_lag': 0, 'Ethereum_lag': 0, 'Dogecoin_lag': 2, 'Cardano_lag': 2, 'USD Coin_lag': 0} \n",
    "ar_orders['M1'] = {'p': 1, 'd': 3, 'q': 0, 'P': 2, 'D': 1, 'Q': 1, 'Bitcoin_lag': 0, 'Tether_lag': 0, 'Litecoin_lag': 1, 'XRP_lag': 3, 'Ethereum_lag': 0, 'Dogecoin_lag': 6, 'USD Coin_lag': 1} \n",
    "ar_orders['GDP'] = {'p': 1, 'd': 1, 'q': 0, 'P': 0, 'D': 1, 'Q': 2, 'Bitcoin_lag': 0, 'Tether_lag': 1, 'Litecoin_lag': 1, 'Ethereum_lag': 6} \n",
    "ar_orders['IM'] = {'p': 1, 'd': 1, 'q': 0, 'P': 1, 'D': 1, 'Q': 2, 'Tether_lag': 2, 'Cardano_lag': 2, 'USD Coin_lag': 2} \n",
    "ar_orders['EX'] = {'p': 1, 'd': 1, 'q': 0, 'P': 2, 'D': 1, 'Q': 1, 'Tether_lag': 3, 'Cardano_lag': 0, 'Ethereum_lag': 1} \n",
    "ar_orders['CC'] = {'p': 1, 'd': 1, 'q': 0, 'P': 1, 'D': 1, 'Q': 0, 'Tether_lag': 4, 'XRP_lag': 0, 'Cardano_lag': 0, 'USD Coin_lag': 0}\n",
    "# ar_orders['PC1_macro'] = {'p': 1, 'd': 3, 'q': 0, 'P': 2, 'D': 1, 'Q': 1, \n",
    "#                           'Bitcoin_lag': 2, 'Tether_lag': 0, 'Litecoin_lag': 2, 'XRP_lag': 4, 'Ethereum_lag': 1, 'Dogecoin_lag': 4, \n",
    "#                           'Cardano_lag': 1, 'USD Coin_lag': 4, 'PC1_crypto_lag': 1, 'PC2_crypto_lag': 1, 'VIX_lag': 0}\n",
    "# ar_orders['PC2_macro'] = {'p': 1, 'd': 1, 'q': 0, 'P': 0, 'D': 1, 'Q': 2, \n",
    "#                           'Bitcoin_lag': 0, 'Tether_lag': 0, 'Litecoin_lag': 0, 'XRP_lag': 0, 'Ethereum_lag': 0, 'Dogecoin_lag': 1, \n",
    "#                           'Cardano_lag': 1, 'USD Coin_lag': 2, 'PC1_crypto_lag': 0, 'PC2_crypto_lag': 0, 'VIX_lag': 0}\n",
    "# ar_orders['CC % Change'] = {'p': 2, 'd': 0,'q': 0, 'P': 2, 'D': 1, 'Q': 0}\n",
    "# ar_orders['VIX'] = {'p': 1, 'd': 0,'q': 0, 'P': 1, 'D': 1, 'Q': 0}\n",
    "# ar_orders['MOVE'] = {'p': 1, 'd': 1,'q': 0, 'P': 1, 'D': 0, 'Q': 0}\n",
    "# ar_orders['vol_LFPR'] = {'p': 1, 'd': 1,'q': 0}\n",
    "# ar_orders['vol_CPI'] = {'p': 1, 'd': 1, 'q': 0}\n",
    "# ar_orders['vol_r'] = {'p': 1, 'd': 1,'q': 0}\n",
    "# ar_orders['vol_M1'] = {'p': 1, 'd': 1,'q': 0}\n",
    "# ar_orders['vol_GDP'] = {'p': 1, 'd': 1, 'q': 0}\n",
    "# ar_orders['vol_IM'] = {'p': 1, 'd': 2,'q': 0}\n",
    "# ar_orders['vol_EX'] = {'p': 1, 'd': 1, 'q': 0}\n",
    "# ar_orders['vol_CC'] = {'p': 1, 'd': 1,'q': 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7277666",
   "metadata": {},
   "source": [
    "### Checking Model Assumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780a01a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model_assumptions(y_train, X_train, model_residuals):\n",
    "    # Add constant to X\n",
    "    X_const = add_constant(X_train)\n",
    "    \n",
    "    # 1. Breuschâ€“Pagan test for heteroskedasticity\n",
    "    ols_model = OLS(y_train, X_const).fit()\n",
    "    bp_stat, bp_pvalue, _, _ = het_breuschpagan(ols_model.resid, X_const)\n",
    "\n",
    "    # 2. Shapiro-Wilk test for normality\n",
    "    shapiro_stat, shapiro_p = shapiro(model_residuals)\n",
    "\n",
    "    # 3. Anderson-Darling test\n",
    "    ad_result = anderson(model_residuals)\n",
    "    ad_stat = ad_result.statistic\n",
    "    ad_crit = list(zip(ad_result.significance_level, ad_result.critical_values))\n",
    "\n",
    "    # 6. Mean of residuals\n",
    "    mean_resid = model_residuals.mean()\n",
    "\n",
    "    # 7. Durbin-Watson test for autocorrelation\n",
    "    dw_stat = durbin_watson(model_residuals)\n",
    "\n",
    "    \n",
    "    return {\n",
    "        \"Breusch-Pagan p\": bp_pvalue,\n",
    "        \"Shapiro p\": shapiro_p,\n",
    "        \"Anderson stat\": ad_stat,\n",
    "        \"Anderson crit\": ad_crit,\n",
    "        \"Mean resid\": mean_resid,\n",
    "        \"Durbin-Watson\": durbin_watson(model_residuals),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c4bc7f",
   "metadata": {},
   "source": [
    "## Testing Significance of All Lag for All Crypto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb09c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_all_exog(df, df_exog, macro, plot=False):\n",
    "    outliers = ['2020-03-01', '2020-04-01', '2020-05-01', '2020-06-01',\n",
    "                '2020-07-01', '2020-08-01', '2020-09-01']\n",
    "\n",
    "    # Get ARIMA orders\n",
    "    order_dict = ar_orders.get(macro, {'p': 1, 'd': 1, 'q': 0, 'P': 1, 'D': 1, 'Q': 0})\n",
    "    p, d, q = order_dict['p'], order_dict['d'], order_dict['q']\n",
    "    P, D, Q = order_dict['P'], order_dict['D'], order_dict['Q']\n",
    "\n",
    "    ### ==== AR Data: Use only macro series ==== ###\n",
    "    df_macro = df[[macro]].dropna().copy()\n",
    "    df_macro = df_macro[~df_macro.index.isin(pd.to_datetime(outliers))]\n",
    "    target_ar = df_macro[macro]\n",
    "    train_endog_ar = target_ar[train_start:train_end]\n",
    "    test_endog_ar = target_ar[train_end:]\n",
    "\n",
    "    ### ==== ARX Data: Use macro + all exog vars with lag 0 ==== ###\n",
    "    # df_exog_clean = df_exog.dropna().copy()\n",
    "    df_exog_clean = df_exog.iloc[:, :27].dropna().copy()\n",
    "\n",
    "    df_exog_clean = df_exog_clean[~df_exog_clean.index.isin(pd.to_datetime(outliers))]\n",
    "\n",
    "\n",
    "    # Align df_exog with df_macro\n",
    "    df_joint = df_macro.join(df_exog_clean, how='inner')\n",
    "    df_joint = df_joint.dropna()\n",
    "\n",
    "    target_arx = df_joint[macro]\n",
    "    exog = df_joint.drop(columns=[macro])\n",
    "\n",
    "    train_endog_arx = target_arx[train_start:train_end]\n",
    "    train_exog = exog[train_start:train_end]\n",
    "    test_endog_arx = target_arx[train_end:]\n",
    "    test_exog = exog[train_end:]\n",
    "\n",
    "    ### ==== Fit AR and ARX Models ==== ###\n",
    "    with warnings.catch_warnings(record=True) as w:\n",
    "        warnings.simplefilter(\"always\", ConvergenceWarning)\n",
    "        ar_model = SARIMAX(train_endog_ar, order=(p, d, q), seasonal_order=(P, D, Q, 12), cov_type = 'none')\n",
    "        ar_result = ar_model.fit(disp=False)\n",
    "        arx_model = SARIMAX(train_endog_arx, exog=train_exog, order=(p, d, q), seasonal_order=(P, D, Q, 12), cov_type = 'none')\n",
    "        arx_result = arx_model.fit(disp=False)\n",
    "        print(arx_result.summary())\n",
    "        pvals = arx_result.pvalues\n",
    "        with pd.option_context('display.float_format', lambda x: f\"{x:.7e}\"):\n",
    "             print(pvals)\n",
    "        for warning in w:\n",
    "            if issubclass(warning.category, ConvergenceWarning):\n",
    "                print(f\"[WARNING] Convergence issue in macro: {macro}\")\n",
    "\n",
    "    ### ==== Forecasts ==== ###\n",
    "    pred_ar = ar_result.get_forecast(steps=len(test_endog_ar)).predicted_mean\n",
    "    conf_int_ar = ar_result.get_forecast(steps=len(test_endog_ar)).conf_int()\n",
    "\n",
    "    pred_arx = arx_result.get_forecast(steps=len(test_endog_arx), exog=test_exog).predicted_mean\n",
    "    conf_int_arx = arx_result.get_forecast(steps=len(test_endog_arx), exog=test_exog).conf_int()\n",
    "\n",
    "    # Align indices\n",
    "    pred_ar.index = test_endog_ar.index\n",
    "    pred_arx.index = test_endog_arx.index\n",
    "    conf_int_ar.index = test_endog_ar.index\n",
    "    conf_int_arx.index = test_endog_arx.index\n",
    "\n",
    "    # Residuals\n",
    "    arx_residuals = arx_result.resid[14:]\n",
    "\n",
    "    ### ==== Plotting ==== ###\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(train_endog_ar, label='Training Actual', color='black')\n",
    "        plt.plot(ar_result.fittedvalues, label='AR Fitted', linestyle='--', color='blue')\n",
    "        plt.plot(arx_result.fittedvalues, label='ARX Fitted', linestyle='--', color='red')\n",
    "        plt.title(f\"In-Sample Fitted Values: {macro}\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(macro)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(target_ar[train_start:], label='Actual ' + macro, color='black')\n",
    "        plt.plot(pred_ar, label='AR Forecast', linestyle='--', color='blue')\n",
    "        plt.fill_between(pred_ar.index, conf_int_ar.iloc[:, 0], conf_int_ar.iloc[:, 1], color='blue', alpha=0.1)\n",
    "        plt.plot(pred_arx, label='ARX Forecast', linestyle='--', color='red')\n",
    "        plt.fill_between(pred_arx.index, conf_int_arx.iloc[:, 0], conf_int_arx.iloc[:, 1], color='red', alpha=0.1)\n",
    "        plt.title(\"Out-of-Sample Forecast\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(test_endog_ar, label='Actual', marker='o', color='black')\n",
    "        plt.plot(pred_ar, label='AR Forecast', linestyle='--', marker='x', color='blue')\n",
    "        plt.plot(pred_arx, label='ARX Forecast', linestyle='--', marker='s', color='red')\n",
    "        plt.title(\"Forecast vs Actual (Test Period)\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(macro)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    ### ==== Metrics ==== ###\n",
    "    metrics = [\n",
    "        {\n",
    "            'Model': 'AR',\n",
    "            'MAE': mean_absolute_error(test_endog_ar, pred_ar),\n",
    "            'RMSE': np.sqrt(mean_squared_error(test_endog_ar, pred_ar)),\n",
    "            'R2': r2_score(test_endog_ar, pred_ar),\n",
    "            'MAPE (%)': mean_absolute_percentage_error(test_endog_ar, pred_ar) * 100,\n",
    "            'Order': f'({p},{d},{q})'\n",
    "        },\n",
    "        {\n",
    "            'Model': 'ARX',\n",
    "            'MAE': mean_absolute_error(test_endog_arx, pred_arx),\n",
    "            'RMSE': np.sqrt(mean_squared_error(test_endog_arx, pred_arx)),\n",
    "            'R2': r2_score(test_endog_arx, pred_arx),\n",
    "            'MAPE (%)': mean_absolute_percentage_error(test_endog_arx, pred_arx) * 100,\n",
    "            'Order': f'({p},{d},{q})'\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    assumptions = check_model_assumptions(train_endog_arx[14:], train_exog[14:], arx_residuals)\n",
    "    return pd.DataFrame(metrics).set_index('Model'), assumptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997acd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model_all_exog(df.copy(), df_exog.copy(), 'GDP', plot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f4ff35",
   "metadata": {},
   "source": [
    "## Checking Variable Stationarity, ACF, PACF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef247437",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_stationarity(series):\n",
    "    result = adfuller(series.dropna())\n",
    "    p_value = result[1]\n",
    "    print(f\"ADF test for {series.name}: p-value = {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651cf046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACF and PACF\n",
    "def acf(series, name = 'variable'):\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(10, 6))\n",
    "    plot_acf(series, lags=30, ax=ax[0])\n",
    "    ax[0].set_title(f'ACF of {name}')\n",
    "    plot_pacf(series, lags=20, ax=ax[1])\n",
    "    ax[1].set_title(f'PACF of {name}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bccf366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable = 'PC2_macro'\n",
    "# check_stationarity(df[variable])\n",
    "# series = df[variable].dropna()\n",
    "# acf(series, variable)\n",
    "# df[f'{variable}_diff'] = df[variable].diff()\n",
    "# series = df[f'{variable}_diff'].dropna()\n",
    "# acf(series, f'{variable}_diff')\n",
    "# check_stationarity(df[f'{variable}_diff'])\n",
    "\n",
    "# df[f'{variable}_diff_diff'] = df[f'{variable}_diff'].diff()\n",
    "# series = df[f'{variable}_diff_diff'].dropna()\n",
    "# acf(series, f'{variable}_diff_diff')\n",
    "# check_stationarity(df[f'{variable}_diff_diff'])\n",
    "\n",
    "# df[f'{variable}_diff_diff_diff'] = df[f'{variable}_diff_diff'].diff()\n",
    "# series = df[f'{variable}_diff_diff_diff'].dropna()\n",
    "# acf(series, f'{variable}_diff_diff_diff')\n",
    "# check_stationarity(df[f'{variable}_diff_diff_diff'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aef9e06",
   "metadata": {},
   "source": [
    "## SARIMA(X) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d516ae14",
   "metadata": {},
   "source": [
    "### P, D, Q Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61493cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# P = Q = range(0, 3)\n",
    "# D = [0, 1]\n",
    "# s = 12  \n",
    "# seasonal_combinations = list(product(P, D, Q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc2ebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_best_seasonal_order(y, macro, ar_orders, exog=None, seasonal_period=12, verbose=False):\n",
    "#     best_aic = np.inf\n",
    "#     best_model = None\n",
    "#     best_seasonal_order = None\n",
    "\n",
    "#     # Fixed p, d, q\n",
    "#     order = (\n",
    "#         ar_orders[macro]['p'],\n",
    "#         ar_orders[macro]['d'],\n",
    "#         ar_orders[macro]['q']\n",
    "#     )\n",
    "\n",
    "#     for P, D, Q in seasonal_combinations:\n",
    "#         seasonal_order = (P, D, Q, seasonal_period)\n",
    "\n",
    "#         try:\n",
    "#             with warnings.catch_warnings():\n",
    "#                 warnings.filterwarnings(\"ignore\")\n",
    "#                 model = SARIMAX(\n",
    "#                     y,\n",
    "#                     exog=exog,\n",
    "#                     order=order,\n",
    "#                     seasonal_order=seasonal_order,\n",
    "#                     enforce_stationarity=False,\n",
    "#                     enforce_invertibility=False\n",
    "#                 )\n",
    "#                 results = model.fit(disp=False)\n",
    "\n",
    "#                 if results.aic < best_aic:\n",
    "#                     best_aic = results.aic\n",
    "#                     best_model = results\n",
    "#                     best_seasonal_order = seasonal_order\n",
    "\n",
    "#                 if verbose:\n",
    "#                     print(f\"Tried SARIMA{order}x{seasonal_order} AIC={results.aic:.2f}\")\n",
    "\n",
    "#         except Exception as e:\n",
    "#             if verbose:\n",
    "#                 print(f\"Failed SARIMA{order}x{seasonal_order}: {e}\")\n",
    "#             continue\n",
    "\n",
    "#     return order, best_seasonal_order, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b4d7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# macro = \"PC2_macro\"\n",
    "# y = df[macro].dropna()\n",
    "\n",
    "# order, best_seasonal_order, best_model = find_best_seasonal_order(y, macro, ar_orders, seasonal_period=12, verbose=True)\n",
    "\n",
    "# print(\"Fixed order:\", order)\n",
    "# print(\"Best seasonal order:\", best_seasonal_order)\n",
    "# print(\"Best AIC:\", best_model.aic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7041ada3",
   "metadata": {},
   "source": [
    "### Running Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9088f93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(df, macro, plot=False):\n",
    "    outliers = ['2020-03-01', '2020-04-01', '2020-04-01', '2020-05-01', '2020-06-01', '2020-07-01', '2020-08-01', '2020-09-01']\n",
    "\n",
    "    order_dict = ar_orders.get(macro, {'p': 1, 'd': 1, 'q': 0, 'P': 1, 'D': 1, 'Q': 0})\n",
    "\n",
    "    # Unpack ARIMA and seasonal orders\n",
    "    p = order_dict['p']\n",
    "    d = order_dict['d']\n",
    "    q = order_dict['q']\n",
    "    P = order_dict['P']\n",
    "    D = order_dict['D']\n",
    "    Q = order_dict['Q']\n",
    "\n",
    "    # Extract asset-specific lag\n",
    "    crypto_lags = {\n",
    "        k.replace('_lag', ''): v\n",
    "        for k, v in order_dict.items()\n",
    "        if k.endswith('_lag') and v is not None\n",
    "    }\n",
    "\n",
    "    ### ==== AR Data: Use only macro series ==== ###\n",
    "    df_macro = df[[macro]].dropna().copy()\n",
    "    df_macro = df_macro[~df_macro.index.isin(pd.to_datetime(outliers))]\n",
    "    target_ar = df_macro[macro]\n",
    "    train_endog_ar = target_ar[train_start:train_end]\n",
    "    test_endog_ar = target_ar[train_end:]\n",
    "\n",
    "    ### ==== ARX Data: Use macro + asset ==== ###\n",
    "    #df_temp = df[[macro, asset]].dropna().copy()\n",
    "    df_temp = df[[macro] + list(crypto_lags.keys())].dropna().copy()\n",
    "    df_temp = df_temp[~df_temp.index.isin(pd.to_datetime(outliers))]\n",
    "\n",
    "    # Create lagged asset columns\n",
    "    for asset, lag in crypto_lags.items():\n",
    "        if lag > 0:\n",
    "            df_temp[f'{asset}_lag{lag}'] = df_temp[asset].shift(lag)\n",
    "            df_temp.drop(columns=[asset], inplace=True)  # optional: drop original\n",
    "        else:\n",
    "            df_temp.rename(columns={asset: f'{asset}_lag0'}, inplace=True)\n",
    "\n",
    "    df_temp = df_temp.dropna()\n",
    "    target_arx = df_temp[macro]\n",
    "    exog_cols = [f'{asset}_lag{lag}' for asset, lag in crypto_lags.items()]\n",
    "    exog = df_temp[exog_cols]\n",
    "    \n",
    "    train_endog_arx = target_arx[train_start:train_end]\n",
    "    train_exog = exog[train_start:train_end]\n",
    "    \n",
    "    test_endog_arx = target_arx[train_end:]\n",
    "    test_exog = exog[train_end:]\n",
    "\n",
    "    ### ==== Fit AR and ARX Models ==== ###\n",
    "    with warnings.catch_warnings(record=True) as w:\n",
    "        warnings.simplefilter(\"always\", ConvergenceWarning)\n",
    "        ar_model = SARIMAX(train_endog_ar, order=(p, d, q), seasonal_order=(P, D, Q, 12))\n",
    "        ar_result = ar_model.fit(disp=False)\n",
    "        arx_model = SARIMAX(train_endog_arx, exog=train_exog, order=(p, d, q), seasonal_order=(P, D, Q, 12))\n",
    "        arx_result = arx_model.fit(disp=False)\n",
    "        print(arx_result.summary())\n",
    "\n",
    "        for warning in w:\n",
    "            if issubclass(warning.category, ConvergenceWarning):\n",
    "                print(f\"[WARNING] Convergence issue in macro: {macro}\")\n",
    "\n",
    "    ### ==== Forecasts ==== ###\n",
    "    pred_ar = ar_result.get_forecast(steps=len(test_endog_ar)).predicted_mean\n",
    "    conf_int_ar = ar_result.get_forecast(steps=len(test_endog_ar)).conf_int()\n",
    "\n",
    "    pred_arx = arx_result.get_forecast(steps=len(test_endog_arx), exog=test_exog).predicted_mean\n",
    "    conf_int_arx = arx_result.get_forecast(steps=len(test_endog_arx), exog=test_exog).conf_int()\n",
    "\n",
    "    # Align index for plotting\n",
    "    pred_ar.index = test_endog_ar.index\n",
    "    pred_arx.index = test_endog_arx.index\n",
    "    conf_int_ar.index = test_endog_ar.index\n",
    "    conf_int_arx.index = test_endog_arx.index\n",
    "\n",
    "    # Filtered residuals\n",
    "    arx_residuals = arx_result.resid[14:]\n",
    "\n",
    "    ### ==== Plotting ==== ###\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(train_endog_ar, label='Training Actual', color='black')\n",
    "        plt.plot(ar_result.fittedvalues, label='AR Fitted', linestyle='--', color='blue')\n",
    "        plt.plot(arx_result.fittedvalues, label='ARX Fitted', linestyle='--', color='red')\n",
    "        plt.title(f\"In-Sample Fitted Values: {macro}\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(macro)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(target_ar[train_start:], label='Actual ' + macro, color='black')\n",
    "        plt.plot(pred_ar, label=f'Forecasted {macro} (AR only)', linestyle='--', color='blue')\n",
    "        plt.fill_between(pred_ar.index, conf_int_ar.iloc[:, 0], conf_int_ar.iloc[:, 1], color='blue', alpha=0.1)\n",
    "        plt.plot(pred_arx, label=f'Forecasted {macro} (ARX with crypto)', linestyle='--', color='red')\n",
    "        plt.fill_between(pred_arx.index, conf_int_arx.iloc[:, 0], conf_int_arx.iloc[:, 1], color='red', alpha=0.1)\n",
    "        plt.title(\"Out-of-Sample Forecast\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(test_endog_ar, label='Actual ' + macro, marker='o', color='black')\n",
    "        plt.plot(pred_ar, label=f'AR Forecast', linestyle='--', marker='x', color='blue')\n",
    "        plt.plot(pred_arx, label=f'ARX Forecast', linestyle='--', marker='s', color='red')\n",
    "        plt.title(\"Forecast vs Actual (Test Period)\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(macro)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # resid_df = arx_residuals.to_frame(name='Residual')\n",
    "        # resid_df.index.name = 'Month'\n",
    "        # # Histogram for trimmed residuals\n",
    "        # plt.figure(figsize=(8, 4))\n",
    "        # sns.histplot(arx_residuals, kde=True, bins=30, color='skyblue')\n",
    "        # plt.title(\"ARX Trimmed Residuals Histogram with KDE\")\n",
    "        # plt.xlabel(\"Residual\")\n",
    "        # plt.ylabel(\"Frequency\")\n",
    "        # plt.tight_layout()\n",
    "        # plt.show()\n",
    "\n",
    "        # # Print only trimmed residuals\n",
    "        # print(resid_df)\n",
    "\n",
    "    ### ==== Metrics ==== ###\n",
    "    metrics = [\n",
    "        {\n",
    "            'Model': 'AR',\n",
    "            'MAE': mean_absolute_error(test_endog_ar, pred_ar),\n",
    "            'RMSE': np.sqrt(mean_squared_error(test_endog_ar, pred_ar)),\n",
    "            'R2': r2_score(test_endog_ar, pred_ar),\n",
    "            'MAPE (%)': mean_absolute_percentage_error(test_endog_ar, pred_ar) * 100,\n",
    "            'Order': f'({p},{d},{q})'\n",
    "        },\n",
    "        {\n",
    "            'Model': 'ARX',\n",
    "            'MAE': mean_absolute_error(test_endog_arx, pred_arx),\n",
    "            'RMSE': np.sqrt(mean_squared_error(test_endog_arx, pred_arx)),\n",
    "            'R2': r2_score(test_endog_arx, pred_arx),\n",
    "            'MAPE (%)': mean_absolute_percentage_error(test_endog_arx, pred_arx) * 100,\n",
    "            'Order': f'({p},{d},{q})'\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    assumptions = check_model_assumptions(train_endog_arx[14:], train_exog[14:], arx_residuals)\n",
    "    return ( pd.DataFrame(metrics).set_index('Model'), assumptions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c95d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_model(df.copy(), 'CPI', plot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf9bcaa",
   "metadata": {},
   "source": [
    "## Rolling Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6174b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_forecast_sarimax(df, macro, train_start, train_end, max_forecast_horizon=None):\n",
    "    outliers = ['2020-03-01', '2020-04-01', '2020-04-01', '2020-05-01', '2020-06-01', '2020-07-01', '2020-08-01', '2020-09-01']\n",
    "    order_dict = ar_orders.get(macro, {'p': 1, 'd': 1, 'q': 0, 'P': 1, 'D': 1, 'Q': 0})\n",
    "    p, d, q = order_dict['p'], order_dict['d'], order_dict['q']\n",
    "    P, D, Q = order_dict['P'], order_dict['D'], order_dict['Q']\n",
    "\n",
    "    crypto_lags = {\n",
    "        k.replace('_lag', ''): v for k, v in order_dict.items()\n",
    "        if k.endswith('_lag') and v is not None\n",
    "    }\n",
    "\n",
    "    df_macro = df[[macro]].dropna().copy()\n",
    "    df_macro = df_macro[~df_macro.index.isin(pd.to_datetime(outliers))]\n",
    "    df_temp = df[[macro] + list(crypto_lags.keys())].dropna().copy()\n",
    "    df_temp = df_temp[~df_temp.index.isin(pd.to_datetime(outliers))]\n",
    "\n",
    "    for asset, lag in crypto_lags.items():\n",
    "        if lag > 0:\n",
    "            df_temp[f'{asset}_lag{lag}'] = df_temp[asset].shift(lag)\n",
    "            df_temp.drop(columns=[asset], inplace=True)\n",
    "        else:\n",
    "            df_temp.rename(columns={asset: f'{asset}_lag0'}, inplace=True)\n",
    "\n",
    "    df_temp = df_temp.dropna()\n",
    "    target_ar = df_macro[macro]\n",
    "    target_arx = df_temp[macro]\n",
    "    exog_cols = [f'{asset}_lag{lag}' for asset, lag in crypto_lags.items()]\n",
    "    exog = df_temp[exog_cols]\n",
    "\n",
    "    # Set rolling window range\n",
    "    train_idx = df_macro.index.get_loc(train_end)\n",
    "    y_full_ar = target_ar.copy()\n",
    "    y_full_arx = target_arx.copy()\n",
    "    exog_full = exog.copy()\n",
    "\n",
    "    pred_ar, pred_arx = [], []\n",
    "    true_vals = []\n",
    "\n",
    "    n_forecast = len(target_ar[train_end:]) if max_forecast_horizon is None else max_forecast_horizon\n",
    "    for i in range(n_forecast - 1):\n",
    "        current_train_end = df_macro.index[train_idx + i]\n",
    "        current_test_time = df_macro.index[train_idx + i + 1]\n",
    "\n",
    "        # AR\n",
    "        y_train_ar = y_full_ar[:current_train_end]\n",
    "        model_ar = SARIMAX(y_train_ar,\n",
    "                            order=(p, d, q), seasonal_order=(P, D, Q, 12))\n",
    "        res_ar = model_ar.fit(disp=False)\n",
    "        forecast_ar = res_ar.get_forecast(steps=1).predicted_mean.iloc[0]\n",
    "        pred_ar.append(forecast_ar)\n",
    "\n",
    "        # ARX\n",
    "        y_train_arx = y_full_arx[:current_train_end]\n",
    "        x_train_arx = exog_full[:current_train_end]\n",
    "        x_test_arx = exog_full.loc[[current_test_time]]\n",
    "\n",
    "        model_arx = SARIMAX(y_train_arx, exog=x_train_arx, order=(p, d, q), seasonal_order=(P, D, Q, 12))\n",
    "        res_arx = model_arx.fit(disp=False)\n",
    "        forecast_arx = res_arx.get_forecast(steps=1, exog=x_test_arx).predicted_mean.iloc[0]\n",
    "        pred_arx.append(forecast_arx)\n",
    "\n",
    "        # Actual\n",
    "        y_true = y_full_ar[current_test_time]\n",
    "        true_vals.append(y_true)\n",
    "\n",
    "    # Convert to Series\n",
    "    forecast_index = df_macro.index[train_idx + 1: train_idx + 1 + n_forecast]\n",
    "    return (\n",
    "        pd.Series(true_vals, index=forecast_index, name='Actual'),\n",
    "        pd.Series(pred_ar, index=forecast_index, name='AR Forecast'),\n",
    "        pd.Series(pred_arx, index=forecast_index, name='ARX Forecast'),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa2aa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual, ar_preds, arx_preds = rolling_forecast_sarimax(df, macro='LFPR', train_start='2017-09-01', train_end='2024-01-01')\n",
    "\n",
    "# Evaluate\n",
    "print(\"AR MAE:\", mean_absolute_error(actual, ar_preds))\n",
    "print(\"ARX MAE:\", mean_absolute_error(actual, arx_preds))\n",
    "\n",
    "# Plot\n",
    "actual.plot(label='Actual', color='black')\n",
    "ar_preds.plot(label='AR Forecast', linestyle='--', color='blue')\n",
    "arx_preds.plot(label='ARX Forecast', linestyle='--', color='red')\n",
    "plt.legend()\n",
    "plt.title(\"Rolling Forecast (SARIMAX)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2f4089",
   "metadata": {},
   "source": [
    "## Assumption Testing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40882256",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_assumptions = []\n",
    "\n",
    "for macro in ar_orders.keys():\n",
    "    try:\n",
    "        metrics, assumptions = run_model(df, macro, plot=False)\n",
    "        result_row = {\n",
    "            \"Macro\": macro,\n",
    "            \"Asset\": asset,\n",
    "            \"Breusch-Pagan p\": assumptions[\"Breusch-Pagan p\"],\n",
    "            \"Shapiro p\": assumptions[\"Shapiro p\"],\n",
    "            \"Anderson stat\": assumptions[\"Anderson stat\"],\n",
    "            \"Mean resid\": assumptions[\"Mean resid\"],\n",
    "        }\n",
    "\n",
    "        # Optionally flatten Anderson critical values at 5% level\n",
    "        for level, crit_val in assumptions[\"Anderson crit\"]:\n",
    "            if level == 5:\n",
    "                result_row[\"Anderson 5% crit\"] = crit_val\n",
    "\n",
    "        all_assumptions.append(result_row)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed for Macro: {macro}\")\n",
    "assumptions_df = pd.DataFrame(all_assumptions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b257a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)  # Show all rows\n",
    "pd.set_option(\"display.max_columns\", None)  # (optional) Show all columns\n",
    "pd.set_option(\"display.width\", None)  # Don't wrap columns\n",
    "pd.set_option(\"display.max_colwidth\", None)  # Don't truncate cell content\n",
    "display(assumptions_df) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12df578",
   "metadata": {},
   "source": [
    "## Finding Optimal Crypto Lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6360dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_relevant_assets(df, macro, crypto_assets, threshold=0.2):\n",
    "    corr = df[[macro] + crypto_assets].corr()[macro].abs()\n",
    "    return [asset for asset in crypto_assets if corr[asset] > threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efeee80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_lag(df, macro, crypto_lags, plot=False):\n",
    "    outliers = ['2020-03-01', '2020-04-01', '2020-05-01', '2020-06-01',\n",
    "                '2020-07-01', '2020-08-01', '2020-09-01']\n",
    "\n",
    "    # Get ARIMA orders\n",
    "    order_dict = ar_orders.get(macro, {'p': 1, 'd': 1, 'q': 0, 'P': 1, 'D': 1, 'Q': 0})\n",
    "    p, d, q = order_dict['p'], order_dict['d'], order_dict['q']\n",
    "    P, D, Q = order_dict['P'], order_dict['D'], order_dict['Q']\n",
    "\n",
    "    ### ==== AR Data: Use only macro series ==== ###\n",
    "    df_macro = df[[macro]].dropna().copy()\n",
    "    df_macro = df_macro[~df_macro.index.isin(pd.to_datetime(outliers))]\n",
    "    target_ar = df_macro[macro]\n",
    "    train_endog_ar = target_ar[train_start:train_end]\n",
    "    test_endog_ar = target_ar[train_end:]\n",
    "\n",
    "    ### ==== ARX Data: Use macro + crypto assets ==== ###\n",
    "    df_temp = df[[macro] + list(crypto_lags.keys())].dropna().copy()\n",
    "    df_temp = df_temp[~df_temp.index.isin(pd.to_datetime(outliers))]\n",
    "\n",
    "    # Create lagged columns\n",
    "    for asset, lag in crypto_lags.items():\n",
    "        if lag > 0:\n",
    "            df_temp[f'{asset}_lag{lag}'] = df_temp[asset].shift(lag)\n",
    "            df_temp.drop(columns=[asset], inplace=True)\n",
    "        else:\n",
    "            df_temp.rename(columns={asset: f'{asset}_lag0'}, inplace=True)\n",
    "\n",
    "    df_temp = df_temp.dropna()\n",
    "    target_arx = df_temp[macro]\n",
    "    exog_cols = [f'{asset}_lag{lag}' for asset, lag in crypto_lags.items()]\n",
    "    exog = df_temp[exog_cols]\n",
    "\n",
    "    train_endog_arx = target_arx[train_start:train_end]\n",
    "    train_exog = exog[train_start:train_end]\n",
    "    test_endog_arx = target_arx[train_end:]\n",
    "    test_exog = exog[train_end:]\n",
    "\n",
    "    ### ==== Fit AR and ARX Models ==== ###\n",
    "    with warnings.catch_warnings(record=True) as w:\n",
    "        warnings.simplefilter(\"always\", ConvergenceWarning)\n",
    "        ar_model = SARIMAX(train_endog_ar, order=(p, d, q), seasonal_order=(P, D, Q, 12))\n",
    "        ar_result = ar_model.fit(disp=False)\n",
    "        arx_model = SARIMAX(train_endog_arx, exog=train_exog, order=(p, d, q), seasonal_order=(P, D, Q, 12))\n",
    "        arx_result = arx_model.fit(disp=False)\n",
    "\n",
    "        for warning in w:\n",
    "            if issubclass(warning.category, ConvergenceWarning):\n",
    "                print(f\"[WARNING] Convergence issue in macro: {macro}\")\n",
    "\n",
    "    ### ==== Forecasts ==== ###\n",
    "    pred_ar = ar_result.get_forecast(steps=len(test_endog_ar)).predicted_mean\n",
    "    conf_int_ar = ar_result.get_forecast(steps=len(test_endog_ar)).conf_int()\n",
    "\n",
    "    pred_arx = arx_result.get_forecast(steps=len(test_endog_arx), exog=test_exog).predicted_mean\n",
    "    conf_int_arx = arx_result.get_forecast(steps=len(test_endog_arx), exog=test_exog).conf_int()\n",
    "\n",
    "    # Align indices\n",
    "    pred_ar.index = test_endog_ar.index\n",
    "    pred_arx.index = test_endog_arx.index\n",
    "    conf_int_ar.index = test_endog_ar.index\n",
    "    conf_int_arx.index = test_endog_arx.index\n",
    "\n",
    "    # Residuals\n",
    "    arx_residuals = arx_result.resid[14:]\n",
    "\n",
    "    ### ==== Plotting ==== ###\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(train_endog_ar, label='Training Actual', color='black')\n",
    "        plt.plot(ar_result.fittedvalues, label='AR Fitted', linestyle='--', color='blue')\n",
    "        plt.plot(arx_result.fittedvalues, label='ARX Fitted', linestyle='--', color='red')\n",
    "        plt.title(f\"In-Sample Fitted Values: {macro}\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(macro)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(target_ar[train_start:], label='Actual ' + macro, color='black')\n",
    "        plt.plot(pred_ar, label='AR Forecast', linestyle='--', color='blue')\n",
    "        plt.fill_between(pred_ar.index, conf_int_ar.iloc[:, 0], conf_int_ar.iloc[:, 1], color='blue', alpha=0.1)\n",
    "        plt.plot(pred_arx, label='ARX Forecast', linestyle='--', color='red')\n",
    "        plt.fill_between(pred_arx.index, conf_int_arx.iloc[:, 0], conf_int_arx.iloc[:, 1], color='red', alpha=0.1)\n",
    "        plt.title(\"Out-of-Sample Forecast\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(test_endog_ar, label='Actual', marker='o', color='black')\n",
    "        plt.plot(pred_ar, label='AR Forecast', linestyle='--', marker='x', color='blue')\n",
    "        plt.plot(pred_arx, label='ARX Forecast', linestyle='--', marker='s', color='red')\n",
    "        plt.title(\"Forecast vs Actual (Test Period)\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(macro)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    ### ==== Metrics ==== ###\n",
    "    metrics = [\n",
    "        {\n",
    "            'Model': 'AR',\n",
    "            'MAE': mean_absolute_error(test_endog_ar, pred_ar),\n",
    "            'RMSE': np.sqrt(mean_squared_error(test_endog_ar, pred_ar)),\n",
    "            'R2': r2_score(test_endog_ar, pred_ar),\n",
    "            'MAPE (%)': mean_absolute_percentage_error(test_endog_ar, pred_ar) * 100,\n",
    "            'Order': f'({p},{d},{q})'\n",
    "        },\n",
    "        {\n",
    "            'Model': 'ARX',\n",
    "            'MAE': mean_absolute_error(test_endog_arx, pred_arx),\n",
    "            'RMSE': np.sqrt(mean_squared_error(test_endog_arx, pred_arx)),\n",
    "            'R2': r2_score(test_endog_arx, pred_arx),\n",
    "            'MAPE (%)': mean_absolute_percentage_error(test_endog_arx, pred_arx) * 100,\n",
    "            'Order': f'({p},{d},{q})'\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    assumptions = check_model_assumptions(train_endog_arx[14:], train_exog[14:], arx_residuals)\n",
    "    return pd.DataFrame(metrics).set_index('Model'), assumptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe9da6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_combo(df, macro, crypto_lags):\n",
    "    try:\n",
    "        metrics_df, _ = run_model_lag(df, macro, crypto_lags, plot=False)\n",
    "        ar_mape = metrics_df.loc['AR', 'MAPE (%)']\n",
    "        arx_mape = metrics_df.loc['ARX', 'MAPE (%)']\n",
    "        improvement = ar_mape - arx_mape\n",
    "        return (crypto_lags, improvement)\n",
    "    except Exception as e:\n",
    "        return (None, float('-inf'))\n",
    "\n",
    "def find_optimal_lags_for_macro_parallel(df, macro, crypto_assets, max_lag=3, n_jobs=-1):\n",
    "    from itertools import product\n",
    "    all_lag_combos = list(product(range(max_lag + 1), repeat=len(crypto_assets)))\n",
    "    print(f\"Searching {len(all_lag_combos)} combinations for {macro}...\")\n",
    "\n",
    "    lag_dicts = [dict(zip(crypto_assets, combo)) for combo in all_lag_combos]\n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(evaluate_combo)(df, macro, lags) for lags in tqdm(lag_dicts, desc=f\"Optimizing {macro}\")\n",
    "    )\n",
    "\n",
    "    best_combo, best_score = max(results, key=lambda x: x[1])\n",
    "    print(f\"Best lag combo: {best_combo} with MAPE improvement {best_score:.2f}\")\n",
    "    return best_combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc14422",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro = 'CPI'\n",
    "crypto_assets = asset_list\n",
    "filtered_assets = filter_relevant_assets(df, macro, crypto_assets, threshold = 0.2)\n",
    "print(filtered_assets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfcf83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lags = find_optimal_lags_for_macro_parallel(df, macro, crypto_assets, max_lag=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef2e4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_assets = {asset: lag for asset, lag in best_lags.items() if lag == 0}\n",
    "to_optimize_assets = [asset for asset, lag in best_lags.items() if lag > 0]\n",
    "\n",
    "print(\"Fixed lags:\", fixed_assets)\n",
    "print(\"Assets to optimize further:\", to_optimize_assets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c867b553",
   "metadata": {},
   "outputs": [],
   "source": [
    "if to_optimize_assets:\n",
    "    refined_lags = find_optimal_lags_for_macro_parallel(df, macro, to_optimize_assets, max_lag=3)\n",
    "\n",
    "    # Combine final lags\n",
    "    final_lags = {**fixed_assets, **refined_lags}\n",
    "else:\n",
    "    final_lags = fixed_assets\n",
    "\n",
    "print(\"Final best lags:\", final_lags)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
